{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.ops import io_ops\n",
    "import pathlib\n",
    "import os\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 100, 100, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 98, 98, 128)       1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 32)        36896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 28224)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1806400   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,863,722\n",
      "Trainable params: 1,863,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "35/35 [==============================] - 1s 29ms/step - loss: 13.7968 - accuracy: 0.2000 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/15\n",
      "35/35 [==============================] - 1s 27ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "35/35 [==============================] - 1s 24ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "35/35 [==============================] - 1s 26ms/step - loss: 13.5326 - accuracy: 0.2286 - val_loss: 17.2167 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_dataset_filepath_and_label_train_test_split(dir_path, test_size = 0.3):\n",
    "    audio = os.path.join(dir_path, 'animal_sounds')\n",
    "    unique_labels = [item for item in os.listdir(audio) if os.path.isdir(os.path.join(audio, item))]\n",
    "    audio_ds = pathlib.Path(audio)\n",
    "    list_ds = tf.data.Dataset.list_files(str(audio_ds/'*/*'))\n",
    "    \n",
    "    index = 0\n",
    "    record = {}\n",
    "    for label in unique_labels:\n",
    "        record[label] = index\n",
    "        index += 1        \n",
    "        \n",
    "    df = pd.DataFrame(columns = ['file_path', 'label'])\n",
    "    for f in list_ds.take(50):\n",
    "        filepath = str(f.numpy())\n",
    "        label = record[filepath.split('/')[-2]]\n",
    "        file_name = filepath[1:]\n",
    "        row = pd.Series([file_name, label], index = ['file_path', 'label'])\n",
    "        df = df.append(row, ignore_index=True) \n",
    "        \n",
    "    df_train, df_test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def load_wav_file(filename):\n",
    "  \"\"\"Loads an audio file and returns a float PCM-encoded array of samples.\n",
    "\n",
    "  Args:\n",
    "    filename: Path to the .wav file to load.\n",
    "\n",
    "  Returns:\n",
    "    Numpy array holding the sample data as floats between -1.0 and 1.0.\n",
    "  \"\"\"\n",
    "  with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
    "    wav_filename_placeholder = tf.compat.v1.placeholder(tf.string, [])\n",
    "    wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
    "    wav_decoder = tf.audio.decode_wav(wav_loader, desired_channels=1)\n",
    "    data = sess.run(wav_decoder, feed_dict={wav_filename_placeholder: filename}).audio.flatten()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_dataset(df):\n",
    "    df['feature_ds'] = df['file_path'].apply(lambda x: x[1:-1]).apply(load_wav_file)\n",
    "    num_of_features = 10000#len(df.head(1).feature_ds.values[0])\n",
    "    columns = []\n",
    "    for i in range(num_of_features):\n",
    "        column = 'feature_ds_' + str(i)\n",
    "        columns.append(column)\n",
    "    df_feature = pd.DataFrame(df['feature_ds'].to_list()).loc[:,:9999]\n",
    "    df_feature.columns=columns[:10000]\n",
    "    df_feature['label'] = df['label']\n",
    "    \n",
    "    df_feature = df_feature.fillna(0.0)\n",
    "    \n",
    "    return df_feature\n",
    "\n",
    "def get_FC_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(10000, activation='relu'),\n",
    "        tf.keras.layers.Dense(1000, activation='relu'),\n",
    "        tf.keras.layers.Dense(100, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)])\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=100)\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_CNN_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(tf.keras.layers.Reshape((100, 100, 1), input_shape=(10000,)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(100, 100, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10))\n",
    "    model.summary()\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=10000)\n",
    "    model.compile(optimizer=optimizer,loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "        \n",
    "    return model\n",
    "\n",
    "def get_RNN_model():\n",
    "    model = keras.Sequential()\n",
    "    # Add an Embedding layer expecting input vocab of size 1000, and\n",
    "    # output embedding dimension of size 64.\n",
    "    model.add(layers.Embedding(input_dim=10000, output_dim=64))\n",
    "    # Add a LSTM layer with 128 internal units.\n",
    "    model.add(layers.LSTM(128))\n",
    "    # Add a Dense layer with 10 units.\n",
    "    model.add(layers.Dense(10))\n",
    "    model.summary()\n",
    "    model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def learning_curve_plotting(history):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    # plt.plot(history.history['loss'])\n",
    "    # plt.plot(history.history['val_loss'])\n",
    "    # plt.title('model loss')\n",
    "    # plt.ylabel('loss')\n",
    "    # plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.savefig('learning_curve.jpg')\n",
    "\n",
    "\n",
    "def main(option):\n",
    "    \n",
    "    dir_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "    df_train, df_test = get_dataset_filepath_and_label_train_test_split(dir_path)\n",
    "    ds_train = get_dataset(df_train)\n",
    "    ds_test = get_dataset(df_test)\n",
    "    #df_train.to_csv('audio_list_train.csv')\n",
    "    #df_test.to_csv('audio_list_test.csv')\n",
    "    target_train = ds_train.pop('label')\n",
    "    target_test = ds_test.pop('label')\n",
    "    \n",
    "    if option == 'RF':\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(ds_train, target_train)\n",
    "        pred_test = clf.predict(ds_test)\n",
    "        print (accuracy_score(target_test, pred_test))\n",
    "        \n",
    "    elif option == 'FC':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((ds_train.values, target_train.values))\n",
    "        train_dataset = train_dataset.shuffle(len(ds_train)).batch(1)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((ds_test.values, target_test.values))\n",
    "        test_dataset = test_dataset.shuffle(len(ds_test)).batch(1)\n",
    "        model = get_FC_model()\n",
    "        history = model.fit(train_dataset, validation_data = test_dataset, epochs=15)\n",
    "        learning_curve_plotting(history)\n",
    "\n",
    "    elif option == 'CNN':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((ds_train.values, target_train.values))\n",
    "        train_dataset = train_dataset.shuffle(len(ds_train)).batch(1)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((ds_test.values, target_test.values))\n",
    "        test_dataset = test_dataset.shuffle(len(ds_test)).batch(1)\n",
    "        model = get_CNN_model()\n",
    "        history = model.fit(train_dataset, validation_data = test_dataset, epochs=15)\n",
    "        learning_curve_plotting(history)\n",
    "        \n",
    "    elif option == 'RNN':\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((ds_train.values, target_train.values))\n",
    "        train_dataset = train_dataset.shuffle(len(ds_train)).batch(1)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((ds_test.values, target_test.values))\n",
    "        test_dataset = test_dataset.shuffle(len(ds_test)).batch(1)\n",
    "        model = get_RNN_model()\n",
    "        history = model.fit(train_dataset, validation_data = test_dataset, epochs=15)\n",
    "        learning_curve_plotting(history)\n",
    "        \n",
    "    else:\n",
    "        print ('Invaid model option')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    option = 'CNN'\n",
    "    main(option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
